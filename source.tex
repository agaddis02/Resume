%-------------------------
% Resume in Latex
% Author : Adam Gaddis
% Based on: Wilmer Gonzalez
% License : MIT
%------------------------

\documentclass[11pt, a4paper]{article}
\usepackage{latexsym}
\usepackage[empty]{fullpage}
\usepackage{titlesec}
\usepackage{marvosym}
\usepackage[usenames,dvipsnames]{color}
\usepackage{verbatim}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage[english]{babel}
\usepackage{tabularx}

% Page coloring, fonts, and logos
\usepackage{pagecolor}
\usepackage{lato}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{fontawesome}
% ---

\pagestyle{fancy}
\fancyhf{} % clear all header and footer fields
\fancyfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

% Adjust margins
\addtolength{\oddsidemargin}{-0.5in}
\addtolength{\evensidemargin}{-0.5in}
\addtolength{\textwidth}{1in}
\addtolength{\topmargin}{-.5in}
\addtolength{\textheight}{1.0in}
\urlstyle{same}
\raggedbottom
\raggedright
\setlength{\tabcolsep}{0in}
% ---

% Sections formatting
\titleformat{\section}{
  \vspace{-4pt}\scshape\raggedright\large
}{}{0em}{}[\color{black}\titlerule \vspace{-5pt}]
% ---

% Custom commands
\newcommand{\resumeItem}[1]{%2
  \item\small{
    %\textbf{#1}
    #1
    %{: #2 \vspace{-2pt}}
  }
}

\newcommand{\resumeSubheading}[4]{
  \vspace{8pt}\item%-1
    \begin{tabular*}{0.97\textwidth}[t]{l@{\extracolsep{\fill}}r}
      \textbf{#1} & #2 \\
      \textit{\small#3} & \textit{\small #4} \\
    \end{tabular*}\vspace{-5pt}
}
\newcommand{\resumeSubSubheading}[2]{
    \vspace{1pt}
    \begin{tabular*}{0.97\textwidth}{l@{\extracolsep{\fill}}r}
      \textit{\small#1} & \textit{\small #2} \\
    \end{tabular*}\vspace{-5pt}
}
\newcommand{\resumeSubItem}[2]{\resumeItem{#1}{#2}\vspace{-4pt}}
\renewcommand{\labelitemii}{$\circ$}
\newcommand{\resumeSubHeadingListStart}{\begin{itemize}[leftmargin=*]}
\newcommand{\resumeSubHeadingListEnd}{\end{itemize}}
\newcommand{\resumeItemListStart}{\begin{itemize}}
\newcommand{\resumeItemListEnd}{\end{itemize}\vspace{-5pt}}

\newcommand{\resumeTech}[2]{
 \underline{#1:} #2
}

\newcommand{\name}[1]{\begin{center}\textsc{\Huge#1}\\\end{center}}
\newcommand{\program}[1]{\begin{center}\textsc{#1}\end{center}}
\newcommand{\contact}[1]{\begin{center}\color{contactgray}{\small#1}\end{center}}

\newcommand{\resumeCondensedItem}[5]{%
  \item \small{%
    \textbf{#1} $|$ \textit{#2} $|$ \textit{#3} $|$ \textit{#4} \\
    \hspace*{1.5em} #5
  }
}
\newenvironment{resume_header}{}{\vspace{0pt}}


\newenvironment{nospacetabbing}{
    \begin{tabbing}
}{\end{tabbing}\vspace{-1.2em}}

% COLOR THEMES SELECTION
% For Light theme un-comment this and comment the Dark theme section below
\colorlet{textcolor}{black}
\colorlet{urlcolor}{blue}
\newcommand{\otherThemeRef}{\text{\href{https://github.com/agaddis02/Resume/raw/master/Adam_Gaddis_Resume_Dark.pdf}{\color{textcolor}{Dark} \color{urlcolor}{\faicon{lightbulb-o}}}}}
\newcommand{\latestVersion}{\text{\href{https://github.com/agaddis02/Resume/raw/master/Adam_Gaddis_Resume_Dark.pdf}{\color{urlcolor}{\faicon{refresh}} \color{textcolor} {Latest} }}}

% For Dark theme un-comment this and comment the Light theme section above
% For Dark theme un-comment this and comment the Light theme section above
% \colorlet{textcolor}{white!80!gray}
% \colorlet{backgroundcolor}{black!30!gray}
% \colorlet{urlcolor}{blue!25!white}
% \AtBeginDocument{\color{textcolor}}
% \newcommand{\otherThemeRef}{\text{\href{}{\color{urlcolor}{\faicon{lightbulb-o}} \color{textcolor}{Light} }}}
% \newcommand{\latestVersion}{\text{\href{}{\color{urlcolor}{\faicon{refresh}} \color{textcolor} {Latest} }}}

% ---

% DOCUMENT MAIN
\begin{document}

% For Dark theme also un-comment this line:
% \pagecolor{backgroundcolor}


%%%%%%%%%%%%%%%%%%%%%%%%%%
%     HEADER    %
%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{tabular*}{\textwidth}{l@{\extracolsep{\fill}}r}
    \textsl{\small \latestVersion} & \textsl{\small \otherThemeRef}
\end{tabular*}

\begin{resume_header}
    \name{\text{\href{https://www.linkedin.com/in/adam-t-gaddis-/}{\color{urlcolor}{\faicon{linkedin}} \color{textcolor} Adam T.Gaddis }}}
    \program{ IT \& Data Infrastructure Leader | Governance, Enablement, Impact}
    \contact
    {
        \text{\href{mailto:ag.lsec@icloud.com}{\color{urlcolor}{\faicon{envelope}} \color{textcolor} ag.lsec@icloud.com}}
        \hspace{1cm}
        \text{\href{https://github.com/agaddis02}{\color{urlcolor}{\faicon{github}} \color{textcolor}  agaddis02}}
        \hspace{1cm}
        \text{\color{urlcolor}{\faicon{phone}} \color{textcolor}{(214) 335 - 3200}}
        \hspace{1cm}
        \text{\color{urlcolor}{\faicon{code}} \color{textcolor}{Python, C\#, Go, Rust, Swift}}
    }
\end{resume_header}

\section{Executive Summary}
\text{
  Data-Focused IT Leader with 6+ years of experience designing scalable data platforms, building cloud-native infrastructure, and driving enterprise-wide data governance. I bring full-stack fluency across the data life-cycle, from analytics to engineering to architecture, paired with hands-on IT experience in SCADA, VPNs, and on-prem environments. Positioned for IT management or lead IC roles in data engineering, platforms, or infrastructure, I excel at bridging technical execution with strategic enablement. I specialize in building not only resilient systems but also the governance frameworks, documentation, and data standards that ensure long-term organizational value. Beyond my professional work, I mentor high school students in robotics (FRC), leading software education and managing a \$80K+ annual nonprofit budget. I bring the same operational discipline and mission-driven leadership to community work as I do to enterprise-scale data problems, making me equally prepared for technical leadership and advisory roles.
} \\
\vspace{6pt}
\textit{Board & Advisory: Proven operational leadership in nonprofit STEM education with budgetary control, executive stakeholder engagement, and governance alignment. Experienced in building infrastructure, compliance systems, and educational pipelines, well-positioned for board and advisory contributions in tech-forward organizations.}







%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Experience    %
%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%
%    Cloudflare    %
%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experience}
\resumeSubHeadingListStart
  \resumeSubheading
    {Cloudflare}{Dallas, TX (Remote)}
    {Data Engineer}{May 2024 – Present}
    \resumeItemListStart
      \resumeItem{Mid-level Data Engineer working on the BI team to support internal-facing data applications and large-scale ingestion pipelines.}
      \resumeItem{Created, owned, and currently maintain the platform operations for the Interim Variable Billing project—a direct revenue-generating initiative recouping \$40M in quarterly revenue.}
      \resumeItem{Implemented a Retrieval-Augmented Generation (RAG) AI model for Cloudflare’s internal chatbot on the Lighthouse platform. Built a data pipeline to load hundreds of internal wikis into Cloudflare Vectorize and integrated with Cloudflare Workers to enable seamless AI-assisted internal search.}
      \resumeItem{Designed and implemented native data quality checks within our Go-based ingestion framework using DuckDB, enabling efficient in-line validation during ingestion.}
      \resumeItem{Delivered multiple internal presentations across both the Lighthouse sub-team and the 80+ member BI organization, covering topics such as RAG implementation, ClickHouse vs. Postgres, and ingestion architecture.}
      \resumeItem{Proposed a cost-saving redesign to eliminate reliance on Spark/Dataproc by migrating transformations to Rust-based DataFusion and/or DBT, significantly reducing compute cost.}
      \resumeItem{Developed and maintained multiple data pipelines using Cloudflare’s internal Go-based ingestion framework.}
      \resumeItem{Recognized as the U.S. timezone lead for the Lighthouse platform due to consistent ownership and leadership in debugging and delivery.}
      \resumeItem{Developed reusable ingestion pipelines to support syncing across a variety of structured and semi-structured data sources.}
    \resumeItemListEnd
    \resumeTech{Technologies}{Typescript, Scala, GCP, Bigquery, Clickhouse, Docker, Kubernetes, Cloudflare Products: (Workers AI, Workers, Vectorize, R2) }

%%%%%%%%%%%%%%%%%%%%%%%%%%
%    Adam Gaddis Consulting    %
%%%%%%%%%%%%%%%%%%%%%%%%%%
    \resumeSubheading
      {Adam Gaddis IT \& Data Consulting}{Dallas, TX}
      {Founder}{April 2022 – Present}
      \resumeItemListStart
        \resumeItem{Provide IT and data consulting services to a variety of clients, with a focus on the oil and gas industry.}
        \resumeItem{Helped multiple clients design and implement modern data infrastructure, automating ingestion and storage from key energy data providers such as Enverus, IHS, and ComboCurve.}
      \resumeItemListEnd
    \resumeTech{Technologies}{Snowflake, Azure, GCP, Combocurve, PowerBI, Spotfire, Databricks, DBT, SSO, IOT, SCADA, SQL Server, Tailscale, Spark}

%%%%%%%%%%%%%%%%%%%%%%%%%%
%    Arch Energy Partners    %
%%%%%%%%%%%%%%%%%%%%%%%%%%
\resumeSubheading
  {Arch Energy Partners}{Dallas, TX (Hybrid)}
  {Head of Data \& IT}{Mar. 2023 – Present}
  \resumeItemListStart
    \resumeItem{As the founding Data / IT Hire at a dynamic oil and gas company, led the design and management of all software and data infrastructure, working autonomously to deliver scalable, efficient solutions.}
    \resumeItem{Managed day-to-day IT operations: provisioned virtual machines, maintained the office VPN system, and enforced cloud spend budgets.}
    \resumeItem{Developed robust data ingestion pipelines using Go, C\#, and Python to integrate data from multiple sources. Leveraged PySpark on Databricks to process over 500 million daily well production records.}
    \resumeItem{Built custom tools to track and monitor active oil wells with real-time analytics. Developed a Python-based ELT pipeline to streamline accounting data integration into the data warehouse.}
    \resumeItem{Established and maintained a multi-cloud environment across GCP, AWS, and Azure, optimizing for cost and performance. Pioneered centralized warehousing using BigQuery.}
    \resumeItem{Eliminated reliance on third-party IT vendors and consultants by internalizing all infrastructure operations.}
    \resumeItem{Implemented a robust PySpark-based replication system for ingesting well data from Enverus \& other RDS based providers.}
    \resumeItem{Designed the "Wells in Pay" Spotfire dashboard for Land and Accounting teams, providing immediate insight into well status (e.g., pay, active, pending) and recovering missed payments.}
    \resumeItem{Centralized all transformation logic using Google Dataform to enforce consistency and transparency.}
    \resumeItem{Engineered multiple Google Cloud Functions to automate and enhance data transformation and storage processes.}
    \resumeItem{Converted to consultant in May 2024.}
\resumeItemListEnd
\resumeTech{Technologies}{Go, GCP, Bigquery, S3, GCS, Cloud Functions, Databricks, Apache Spark, SSO \& Oauth, Spotfire, Geopandas, DBT/Dataform}



%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Bank of America    %
%%%%%%%%%%%%%%%%%%%%%%%%%%
\resumeSubheading
      {Bank of America}{Dallas, TX (Hybrid)}
      {AVP Data Engineer II}{Sep. 2022 — Mar. 2023}
      \resumeItemListStart
      \resumeItem{Led the establishment of SDLC practices for the team, transitioning code to a centralized Bitbucket repository and meticulously documenting all ongoing systems.}
      \resumeItem{Overhauled real-time text-based data segments of the data warehouse, converting SQL Server scripts and SSIS packages into efficient PySpark code and Kafka streams, achieving processing of hundreds of millions of data points in near real-time.}
      \resumeItem{Led modernization effort in transition to modern data tools, identified transition plan from SQL Server to Azure Synapse.}
      \resumeItem{Successfully developed a Flask-based web application to revamp a report tracking system for a sister team, managing and updating over 1000 internal reports encompassing more than 500,000 data points.}
      \resumeItem{Spearheaded the continuous integration and continuous deployment (CI/CD) processes using Bitbucket and Jenkins, ensuring seamless and efficient deployment of software updates.}
\resumeItemListEnd
\resumeTech{Technologies}{Azure, Hadoop, MapReduce, HDFS, Sqoop, Impala, Azure Synapse}


%%%%%%%%%%%%%%%%%%%%%%%%%%
%     LOOP    %
%%%%%%%%%%%%%%%%%%%%%%%%%%

\resumeSubheading
      {LOOP}{Dallas, TX (Remote)}
      {Senior Data Engineer}{April 2022 — Sep. 2022}
      \resumeItemListStart
        \resumeItem{Led key data engineering initiatives, focusing on building and managing robust data pipelines, remediating data governance issues, and centralizing data for company-wide analysis.}
        \resumeItem{Implemented and configured GCP-hosted Airflow (Cloud Composer), centralizing all pipeline scheduling into a unified orchestration system to improve data lineage and dependency management.}
        \resumeItem{Collaborated with a third-party data provider to develop Version 2 of our internal quoting model, deployed via Vertex AI \& developed in C\#, resulting in a 75\% increase in the “Sign on First Quote” conversion rate.}
        \resumeItem{Resolved data discrepancies across vendors, from the policy administration system to the location tracking provider, by producing a fully approved, centralized data dictionary to enforce clarity and governance.}
        \resumeItem{Developed integration workflows to sync BigQuery data with Zendesk, fully automating the process of updating customer and lead records across sales and support platforms.}
      \resumeItemListEnd
      \resumeTech{Technologies}{Docker, GCP (Cloud Storage, Vertex AI, BigQuery, Cloud Composer), ERD, Data Governance}\\



\resumeSubheading
      {Previous Experience Cont.}{Pre: April 2022}
      {All roles predating 2022, condensed, see \href{https://www.linkedin.com/in/adam-t-gaddis-/}{\textbf{LinkedIn}} for full information on each of these roles}{Jun. 2019 – Apr. 2022}
     \resumeItemListStart
        %%%%%%%%%%%%%%%%%%%%%%%%%%
        %     Southwest Airlines    %
        %%%%%%%%%%%%%%%%%%%%%%%%%%
        \resumeCondensedItem
          {Southwest Airlines}
          {Data Platform Engineer Intern}
          {Jan. 2022 — April 2022}
          {Dallas, TX}
          {Automated X12 EDI invoice ingestion using a custom Python parser, Airflow, and Postgres; supported ERP transformation planning and deployed pipelines via Docker and Jenkins.}
        %%%%%%%%%%%%%%%%%%%%%%%%%%
        %     Goldman Sachs    %
        %%%%%%%%%%%%%%%%%%%%%%%%%%
        \resumeCondensedItem
          {Goldman Sachs}
          {Data Platform Engineer Intern}
          {Jun. 2021 — Aug. 2021}
          {Dallas, TX}
          {Built internal Python tools and libraries to streamline audit data workflows, improved test coverage from 70\% to 91\%, and reconciled on-prem vs. cloud schema mismatches for critical data systems.}
        %%%%%%%%%%%%%%%%%%%%%%%%%%
        %     UNT Dallas    %
        %%%%%%%%%%%%%%%%%%%%%%%%%%
        \resumeCondensedItem
          {University of North Texas at Dallas}
          {Lead Analytics Engineer}
          {Aug. 2020 — Dec. 2021}
          {Dallas, TX}
          {Led analytics and reporting efforts across Power BI, SAS, and Oracle; managed data requests, state reporting pipelines, and a team of five while ensuring full compliance with Texas education standards.}
        %%%%%%%%%%%%%%%%%%%%%%%%%%
        %     Scout Energy Partners    %
        %%%%%%%%%%%%%%%%%%%%%%%%%%
        \resumeCondensedItem
          {Scout Energy Partners}
          {Data Platform Engineer}
          {Jun. 2019 — Aug. 2020}
          {Dallas, TX}
          {Built and maintained SCADA data infrastructure, C\# web apps, predictive models, and Spotfire dashboards for oil production analytics while supporting hybrid IT operations and Azure SQL Server development.}
     \resumeItemListEnd
     \resumeTech{Technologies}{Python, PyPI, Docker, Kubernetes, Azure, SQL Server, Oracle, Postgres, PowerBI, Tableau, Spotfire, Geopandas, Fiona, Shapely, Confluence, Jenkins}

\resumeSubHeadingListEnd


% ---

%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Skills    %
%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Skills}

% Side-by-side section for compact categories
\begin{tabularx}{\textwidth}{X X}
    \resumeTech{Orchestration}{Airflow, Prefect, Azure Data Factory} &
    \resumeTech{Frameworks}{FastAPI, Spark, DuckDB, DataFusion, Blazor, Iceberg, DBT} \\
\end{tabularx}

% Full-width rows for larger categories
\resumeTech{Analytics \& ML}{PowerBI, Spotfire, Workers AI, Vectorize, Keras, OpenCV} \\
\resumeTech{Governance \& Compliance}{Monte Carlo, Great Expectations, dbdiagram.io} \\
\resumeTech{IT \& Infrastructure}{SCADA, Cisco AnyConnect, Tailscale, Okta (SSO), Windows/Linux Server, On-Prem Systems} \\
\resumeTech{Data Storage}{BigQuery, Snowflake, Databricks, Azure Synapse, SQL Server, Postgres, S3, MongoDB} \\



%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Education    %
%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Education}

    %%%%%%%%%%%%%%%%%%%%%%%%%%
    %     UNTD MBA    %
    %%%%%%%%%%%%%%%%%%%%%%%%%%


    \resumeSubheading
      {University of North Texas at Dallas}{Dallas, TX}
      {M.B.A Strategic Management Concentration | \textit{GPA: 4.0/4.0} } {Aug. 2024 — July. 2025}
      
    %%%%%%%%%%%%%%%%%%%%%%%%%%
    %     UNTD Bachelors    %
    %%%%%%%%%%%%%%%%%%%%%%%%%%
    \resumeSubheading
      {University of North Texas at Dallas}{Dallas, TX}
      {B.B.A in Analytics | \textit{GPA: 3.7/4.0} } {Aug. 2020 — Dec. 2022}

    %%%%%%%%%%%%%%%%%%%%%%%%%%
    %     Richland  Associates    %
    %%%%%%%%%%%%%%%%%%%%%%%%%%
      \resumeSubheading
      {Dallas College}{Dallas, TX}
      {A.A.S in Software Development | \textit{GPA: 3.6/4.0.}}{Aug. 2016 — May. 2020}

  \resumeSubHeadingListEnd
% ---


%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Leadership & Community Engagement    %
%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Leadership \& Community Engagement}

    \resumeSubheading
      {FIRST Robotics Competition Team 3005}{Dallas, TX}
      {Co-executive Director \& Lead Software Mentor}{2020 — Present}
      \resumeItemListStart
        \resumeItem{Lead mentor and administrator for FRC Team 3005 and FTC teams at Emmett J. Conrad High School in Dallas ISD, serving students in the Vickery Meadows area—a designated refugee community with highly diverse and underserved demographics.}
        \resumeItem{Contributed 1000+ hours annually mentoring students and managing team operations, including software education, IT infrastructure, and team logistics.}
        \resumeItem{Oversaw cloud infrastructure and IT systems, leveraging nonprofit credits and mentoring students in the development of scouting, data collection, and analytics apps used during competition.}
        \resumeItem{Assumed full leadership of the program in 2025 alongside my wife, taking responsibility for administration, budgeting, grant writing, and maintaining relationships with school leadership and key sponsors such as the Vickery Meadows Youth Foundation.}
        \resumeItem{Manage an annual nonprofit budget of \$60,000–\$80,000 to fund robotics competitions, equipment, travel, and outreach, ensuring long-term sustainability and community impact.}
        \resumeItem{Lead all software and IT initiatives, including robot programming, while fostering student-driven development in a hands-on, collaborative learning environment.}
        \resumeItem{Mentor approximately 30 students annually and support competitive excellence, including back-to-back Texas UIL State Championship titles.}
    \resumeItemListEnd



\end{document}

